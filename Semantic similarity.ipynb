{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9a2e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.33.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vtung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6132fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128  # Maximum length of input sentence to the model.\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "# Labels in our dataset.\n",
    "labels = [\"similar\", \"not_similar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77202c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data in\n",
    "train_df = pd.read_csv(\"train.tsv\", sep='\\t', on_bad_lines='skip')\n",
    "test_df = pd.read_csv(\"test.tsv\", sep='\\t', on_bad_lines='skip')\n",
    "dev_df = pd.read_csv(\"dev.tsv\", sep='\\t', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a17fa0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples: 3458\n",
      "Total test samples: 1639\n",
      "Total dev samples: 480\n"
     ]
    }
   ],
   "source": [
    "# Shape of the data\n",
    "print(f\"Total train samples: {train_df.shape[0]}\")\n",
    "print(f\"Total test samples: {test_df.shape[0]}\")\n",
    "print(f\"Total dev samples: {dev_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a1e69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>#1 ID</th>\n",
       "      <th>#2 ID</th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>702876</td>\n",
       "      <td>702977</td>\n",
       "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
       "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2108705</td>\n",
       "      <td>2108831</td>\n",
       "      <td>Yucaipa owned Dominick's before selling the ch...</td>\n",
       "      <td>Yucaipa bought Dominick's in 1995 for $693 mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1330381</td>\n",
       "      <td>1330521</td>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10, the ship's owners had published an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3344667</td>\n",
       "      <td>3344648</td>\n",
       "      <td>Around 0335 GMT, Tab shares were up 19 cents, ...</td>\n",
       "      <td>Tab shares jumped 20 cents, or 4.6%, to set a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1236820</td>\n",
       "      <td>1236712</td>\n",
       "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
       "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quality    #1 ID    #2 ID  \\\n",
       "0        1   702876   702977   \n",
       "1        0  2108705  2108831   \n",
       "2        1  1330381  1330521   \n",
       "3        0  3344667  3344648   \n",
       "4        1  1236820  1236712   \n",
       "\n",
       "                                           #1 String  \\\n",
       "0  Amrozi accused his brother, whom he called \"th...   \n",
       "1  Yucaipa owned Dominick's before selling the ch...   \n",
       "2  They had published an advertisement on the Int...   \n",
       "3  Around 0335 GMT, Tab shares were up 19 cents, ...   \n",
       "4  The stock rose $2.11, or about 11 percent, to ...   \n",
       "\n",
       "                                           #2 String  \n",
       "0  Referring to him as only \"the witness\", Amrozi...  \n",
       "1  Yucaipa bought Dominick's in 1995 for $693 mil...  \n",
       "2  On June 10, the ship's owners had published an...  \n",
       "3  Tab shares jumped 20 cents, or 4.6%, to set a ...  \n",
       "4  PG&E Corp. shares jumped $1.63 or 8 percent to...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde87e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3458 entries, 0 to 3457\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Quality    3458 non-null   int64 \n",
      " 1   #1 ID      3458 non-null   int64 \n",
      " 2   #2 ID      3458 non-null   int64 \n",
      " 3   #1 String  3458 non-null   object\n",
      " 4   #2 String  3441 non-null   object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 135.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35106132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete null objects\n",
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "dev_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7a4bfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3441 entries, 0 to 3457\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Quality    3441 non-null   int64 \n",
      " 1   #1 ID      3441 non-null   int64 \n",
      " 2   #2 ID      3441 non-null   int64 \n",
      " 3   #1 String  3441 non-null   object\n",
      " 4   #2 String  3441 non-null   object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 161.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a785cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train target distribution\n",
      "Quality\n",
      "1    2316\n",
      "0    1125\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Train target distribution\n",
    "print(\"Train target distribution\")\n",
    "print(train_df.Quality.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4e8111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid target distribution\n",
      "Quality\n",
      "1    330\n",
      "0    146\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Valid target distribution\n",
    "print(\"Valid target distribution\")\n",
    "print(dev_df.Quality.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "103a176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"similarity\"] = train_df[\"Quality\"].apply(\n",
    "    lambda x: \"not_similar\" if x == 0 else \"similar\"\n",
    ")\n",
    "y_train = tf.keras.utils.to_categorical(train_df.Quality, num_classes=2)\n",
    "\n",
    "dev_df[\"similarity\"] = train_df[\"Quality\"].apply(\n",
    "    lambda x: \"not_similar\" if x == 0 else \"similar\"\n",
    ")\n",
    "y_dev = tf.keras.utils.to_categorical(dev_df.Quality, num_classes=2)\n",
    "\n",
    "test_df[\"similarity\"] = train_df[\"Quality\"].apply(\n",
    "    lambda x: \"not_similar\" if x == 0 else \"similar\"\n",
    ")\n",
    "y_test = tf.keras.utils.to_categorical(test_df.Quality, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e255d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"Generates batches of data.\n",
    "\n",
    "    Args:\n",
    "        sentence_pairs: Array of premise and hypothesis input sentences.\n",
    "        labels: Array of labels.\n",
    "        batch_size: Integer batch size.\n",
    "        shuffle: boolean, whether to shuffle the data.\n",
    "        include_targets: boolean, whether to incude the labels.\n",
    "\n",
    "    Returns:\n",
    "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n",
    "        (or just `[input_ids, attention_mask, `token_type_ids]`\n",
    "         if `include_targets=False`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sentence_pairs,\n",
    "        labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        include_targets=True,\n",
    "    ):\n",
    "        self.sentence_pairs = sentence_pairs\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.include_targets = include_targets\n",
    "        # Load our BERT Tokenizer to encode the text.\n",
    "        # We will use base-base-uncased pretrained model.\n",
    "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n",
    "            \"bert-base-uncased\", do_lower_case=True\n",
    "        )\n",
    "        self.indexes = np.arange(len(self.sentence_pairs))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch.\n",
    "        return len(self.sentence_pairs) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieves the batch of index.\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        sentence_pairs = self.sentence_pairs[indexes]\n",
    "\n",
    "        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n",
    "        # encoded together and separated by [SEP] token.\n",
    "        encoded = self.tokenizer.batch_encode_plus(\n",
    "            sentence_pairs.tolist(),\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            pad_to_max_length=True,\n",
    "            return_tensors=\"tf\",\n",
    "        )\n",
    "\n",
    "        # Convert batch of encoded features to numpy array.\n",
    "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
    "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
    "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
    "\n",
    "        # Set to true if data generator is used for training/validation.\n",
    "        if self.include_targets:\n",
    "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
    "            return [input_ids, attention_masks, token_type_ids], labels\n",
    "        else:\n",
    "            return [input_ids, attention_masks, token_type_ids]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
    "        if self.shuffle:\n",
    "            np.random.RandomState(42).shuffle(self.indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca2020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
